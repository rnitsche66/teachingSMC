*****************************************************************
Review of

Deep Reinforcement Learning-Based Pitch Control for Floating
Offshore Wind Turbines (FOWT)

*****************************************************************

This paper proposes the design of a deep reinforcement learning (DRL)
controller for FOWTs and compares the controller performance with a
classical approach (a PI collective blade pith controller) in
simulation.

For this a DRL concept with an TRPO Algorithm is used. The approach is
clearly explained.

A lot of typos are throughout the paper, eqautions are not numbered at
all. For better readability, it would be very helpful to number
equations and refer to them throughout the text for explanation.

Only simulation results are shown and results for the training data of
the DLR. To show the power of such an data-driven approach it is
necessary excite the system with non training but test data. 


Reinforcement Learning (RL) is based on rewarding expecting
behaviour! But what happens, if something unexpected happens, which
one didn't think of so far, but is feasible, anyway?

'only' simulation results are presented to show the performance of the
DRL with an TRPO approach.

The control goal is to track the electrical power of the turbine while
reducing any platform movement.




Page 1:
what is operating area III / operating zone III

But what is the control objective - this is not clarified in the
Introduction, but later on.


Page 3:
How to chose, i.e.discount factor for gamma (here choosen to be 0.99)

Page 4:
left column,

what is theta?: There exists several thetas:
theta_o ld, theatold, theta_{old} ,...
This paramete is introduce / explained after it is used several times.

However, one can roghly follow the idea behind the algo => ok

right column, why has the observation space vector no name?

All the equations throughout the paper have no number -> therefore
it's hard ot read and navigate throughout the paper.


Page 5:
Figure 5: What can be seen in this figure? Axis are not labeled!
Section IV-A: no text only a figure ????????

How does the controller behave if the system is excited with non
training data - that's the key point!

IV-B: Discussion
Controller comparison: comparing the control errors is much more
meaningful / informative



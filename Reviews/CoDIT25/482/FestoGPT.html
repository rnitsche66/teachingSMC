<!DOCTYPE html>
<!-- saved from url=(0022)https://gpt.festo.net/ -->
<html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <link rel="icon" href="https://gpt.festo.net/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#0091dc">
    <meta name="description" content="Festo web app">
    <link rel="apple-touch-icon" href="https://gpt.festo.net/apple-touch-icon.png">
    <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="https://gpt.festo.net/app.webmanifest">

    <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
    <title>FestoGPT</title>
    <script type="module" crossorigin="" src="./FestoGPT_files/index-CBMP0JjH.js.Herunterladen"></script>
    <link rel="stylesheet" crossorigin="" href="./FestoGPT_files/index-BtgKMjcU.css">
  <link rel="manifest" href="https://gpt.festo.net/manifest.webmanifest"><link rel="modulepreload" as="script" crossorigin="" href="https://gpt.festo.net/assets/Home-7nzmqZm6.js"><link rel="modulepreload" as="script" crossorigin="" href="https://gpt.festo.net/assets/Button-CP6cCHoC.js"><link rel="stylesheet" crossorigin="" href="./FestoGPT_files/Button-BnN1iPxa.css"><link rel="stylesheet" crossorigin="" href="./FestoGPT_files/Home-qeWdbuew.css"></head>
  <body data-theme="light">
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root"><div class="flex flex-col"><header class="fwe-fixed-header"><nav class="fwe-navbar bdai-navbar"><div class="fwe-container"><div class="app-title-container">FestoGPT</div><div class="fwe-button-container"><div class="fwe-navbar-menu"><button class="fwe-navbar-menu-button"><i class="fwe-icon fwe-icon-people-user"></i><span class="fwe-d-none fwe-d-sm-block">Rainer</span></button></div><div class="fwe-navbar-menu"><button class="fwe-navbar-menu-button"><i class="fwe-icon fwe-icon-menu-settings"></i><span class="fwe-d-none fwe-d-sm-block">Settings</span></button></div><div class="fwe-navbar-menu"><button class="fwe-navbar-menu-button"><span class="">English</span></button></div></div><div class="fwe-logo-container"><div class="fwe-festo-logo"></div></div></div></nav></header><div class="fwe-navbar-spacer"></div><div class="flex flex-col gap-2"><div class="body-container"><div class="sidebar-container border-primary toggle-sidebar" aria-hidden="false"><div class="sidebar-header fwe-p-3"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-close" data-testid="icon-html"></i></div></div></button><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-add-2" data-testid="icon-html"></i><div class=""><strong>New chat</strong></div></div></div></button></div><div class="history-container"><div class="history-header fwe-p-3"><strong>History</strong></div><div class="history-list"><div><div class="sidebar-category-title">Today</div><ul class="fwe-list-container"><li class="fwe-list-item fwe-list-item-selected"><div class="flex flex-col gap-2 w-full overflow-x-auto history-card" role="button" tabindex="0"><div><div class="flex flex-row justify-between items-center"><span class="item-title bdai-item-selected">Text Summary Request</span><div class="fwe-popover-menu"><div tabindex="0" role="button" class="fwe-popover-wrapper"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-more fwe-icon-lg" data-testid="icon-html"></i><div class=""></div></div></div></button></div></div></div></div></div></li></ul><div class="custom-list-separator"></div></div><div><div class="sidebar-category-title">Last 7 days</div><ul class="fwe-list-container"><li class="fwe-list-item"><div class="flex flex-col gap-2 w-full overflow-x-auto history-card" role="button" tabindex="0"><div><div class="flex flex-row justify-between items-center"><span class="item-title">Shorten Text Request</span><div class="fwe-popover-menu"><div tabindex="0" role="button" class="fwe-popover-wrapper"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-more fwe-icon-lg" data-testid="icon-html"></i><div class=""></div></div></div></button></div></div></div></div></div></li></ul><div class="custom-list-separator"></div></div><div><div class="sidebar-category-title">Last 30 days</div><ul class="fwe-list-container"><li class="fwe-list-item"><div class="flex flex-col gap-2 w-full overflow-x-auto history-card" role="button" tabindex="0"><div><div class="flex flex-row justify-between items-center"><span class="item-title">Text Summary Request</span><div class="fwe-popover-menu"><div tabindex="0" role="button" class="fwe-popover-wrapper"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-more fwe-icon-lg" data-testid="icon-html"></i><div class=""></div></div></div></button></div></div></div></div></div></li><li class="fwe-list-item"><div class="flex flex-col gap-2 w-full overflow-x-auto history-card" role="button" tabindex="0"><div><div class="flex flex-row justify-between items-center"><span class="item-title">Text Summary Request</span><div class="fwe-popover-menu"><div tabindex="0" role="button" class="fwe-popover-wrapper"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-more fwe-icon-lg" data-testid="icon-html"></i><div class=""></div></div></div></button></div></div></div></div></div></li><li class="fwe-list-item"><div class="flex flex-col gap-2 w-full overflow-x-auto history-card" role="button" tabindex="0"><div><div class="flex flex-row justify-between items-center"><span class="item-title">Text Summary Request</span><div class="fwe-popover-menu"><div tabindex="0" role="button" class="fwe-popover-wrapper"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-more fwe-icon-lg" data-testid="icon-html"></i><div class=""></div></div></div></button></div></div></div></div></div></li><li class="fwe-list-item"><div class="flex flex-col gap-2 w-full overflow-x-auto history-card" role="button" tabindex="0"><div><div class="flex flex-row justify-between items-center"><span class="item-title">Paper Summary Request</span><div class="fwe-popover-menu"><div tabindex="0" role="button" class="fwe-popover-wrapper"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-more fwe-icon-lg" data-testid="icon-html"></i><div class=""></div></div></div></button></div></div></div></div></div></li></ul><div class="custom-list-separator"></div></div></div></div><div class="sidebar-footer footer-pad"><span>All chats unused for 30 days will be deleted.</span></div><div class="pt-3"><div class="feedback-pad flex flex-col"><span class="feedback-text-format">Do you have any feedback for us?</span><button class="feedback-btn-format">Let us know</button></div><div></div></div></div><div class="message-management
            toggle-sidebar
            toggle-toolbox"><div class="fwe-font-size-md banner gap-3"><p>The assistant <strong>Summary Consultant</strong> has been activated</p><button type="button" class="fwe-btn bdai-btn" form="form1"><div class=""><div class="inline-flex justify-center items-center"><div class="">Deactivate</div></div></div></button></div><div class="body-nav-buttons"><div class="sidebar-btns p-3 hide-btns"><button class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link fwe-btn-icon bdai-hover-hero sidebar-toggle-btn"><img class="icon default" alt="Sidebar icon" width="24" height="24" src="data:image/svg+xml,%3c?xml%20version=%271.0%27%20encoding=%27UTF-8%27?%3e%3csvg%20id=%27content%27%20xmlns=%27http://www.w3.org/2000/svg%27%20viewBox=%270%200%2032%2032%27%3e%3crect%20width=%2732%27%20height=%2732%27%20fill=%27none%27/%3e%3cpath%20d=%27m2,4v25h28V4H2Zm5,4h4v17h-4V8Zm19,17h-13V8h13v17Z%27%20fill=%27%23333%27/%3e%3c/svg%3e"><img class="icon hover" alt="Sidebar icon hover" width="24" height="24" src="data:image/svg+xml,%3c?xml%20version=%271.0%27%20encoding=%27UTF-8%27?%3e%3csvg%20id=%27content%27%20xmlns=%27http://www.w3.org/2000/svg%27%20viewBox=%270%200%2032%2032%27%3e%3crect%20width=%2732%27%20height=%2732%27%20fill=%27none%27/%3e%3cpath%20d=%27m2,4v25h28V4H2Zm5,4h4v17h-4V8Zm19,17h-13V8h13v17Z%27%20fill=%27%230091dc%27/%3e%3c/svg%3e"></button><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-add-2 text-xl" data-testid="icon-html"></i></div></div></button></div><div class="toolbox-btns p-3 hide-btns"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-operate-tools text-xl" data-testid="icon-html"></i></div></div></button></div></div><div class="message-container fwe-p-4"><div class="flex flex-row justify-center w-full desktop-expand"><div class="flex flex-col w-full gap-3 blah"><div class="flex flex-row w-full spacing-right false"><div class="prose ai-message w-full p-3"><div class="ai-content"><p>Hello! How can I help you?</p></div><div class="msg-copy-ai"><div tabindex="0" role="button" class=""><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-copy" data-testid="icon-html"></i></div></div></button></div></div></div></div><div class="spacing-left max-w-full false"><div class="human-message"><div class="p-3 human-content"><p>please summarize the following text</p></div><div class="flex self-end"><div tabindex="0" role="button" class=""><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-copy" data-testid="icon-html"></i></div></div></button></div></div></div></div><div class="flex flex-row w-full spacing-right false"><div class="prose ai-message w-full p-3"><div class="ai-content"><div class="assistant-name"><p>AI-Assistant: <strong>Summary Consultant</strong></p></div><p>Please provide the text that you would like me to summarize.</p></div><div class="msg-copy-ai"><div tabindex="0" role="button" class=""><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-copy" data-testid="icon-html"></i></div></div></button></div></div></div></div><div class="spacing-left max-w-full false"><div class="human-message"><div class="p-3 human-content"><p>On the Advancements of the Forward-Forward Algorithm</p><p>Mauricio Ortiz Torres, Markus Lange, Arne P. Raulf</p><p>German Aerospace Center (DLR), Institut for AI-Safety and Security</p><p>Sankt Augustin and Ulm, Germany</p><p>Abstract—The Forward-Forward algorithm has evolved in</p><p>machine learning research, tackling more complex tasks that</p><p>mimic real-life applications. In the last years, it has been</p><p>improved by several techniques to perform better than its</p><p>original version, handling a challenging dataset like CIFAR10</p><p>without losing its flexibility and low memory usage. We have</p><p>shown in our results that improvements are achieved through</p><p>a combination of convolutional channel grouping, learning rate</p><p>schedules, and independent block structures during training</p><p>that lead to a 20% decrease in test error percentage. Additionally,</p><p>to approach further implementations on low-capacity</p><p>hardware projects we have presented a series of lighter models</p><p>that achieve low test error percentages within (21±6)% and</p><p>number of trainable parameters between 164,706 and 754,386.</p><p>This serving also as a basis for our future study on complete</p><p>verification and validation of these kinds of neural networks.</p><p>I. INTRODUCTION</p><p>Given the interest in low-power hardware in aerospace</p><p>projects, the Forward-Forward (FF) Algorithm [1], as introduced</p><p>by its author Geoffrey Hinton in 2022, offers</p><p>great potential for the realization of classification tasks of</p><p>lower memory consumption. The FF algorithm employs two</p><p>principles: First, the layers conforming to the network are</p><p>trained independently by measuring their gradients with a</p><p>locally defined “goodness” loss function, which measures</p><p>the sum of the squares of the activity vectors in each</p><p>layer. Second, the ground truth labels are overlaid on the</p><p>training dataset, to generate a subset of positive and negative</p><p>datasets. The network is trained to maximize its goodness,</p><p>favored by positive data and disfavored by negative data. The</p><p>advantage of working with two forward passes comes during</p><p>its training phase, because, in difference to the traditional</p><p>backpropagation, there is no need for storing neural activities</p><p>or stopping to propagate error derivatives. This approach</p><p>translates in lower memory requirement during training and</p><p>in the inference phase. The algorithm has great flexibility for</p><p>a better hypertuning of its parameters and also for the realization</p><p>of faster and more efficient inferences. Consequently</p><p>making it suitable for its use in low-power hardware and</p><p>possible parallelizations during training [2]. In this paper, we</p><p>will present a summary of the latest research regarding this</p><p>algorithm and its performance. Moreover, we will discuss</p><p>the further improvements that have been made to the general</p><p>structure of the algorithm as well as some of our studies on</p><p>lightweight FF models.</p><p>II. THE FORWARD-FORWARD (FF) ALGORITHM</p><p>A. Original approach</p><p>The architecture of the Forward-Forward algorithm is</p><p>structured as a traditional neural network. However its</p><p>training procedure differs significantly and it has two input</p><p>spaces. These input spaces are given by positive and negative</p><p>samples which are created from the considered dataset of</p><p>interest. Their creation for example for MNIST data is as</p><p>follows: Let Y = {y1, . . . , y10} be the set of labels, i.e., the</p><p>different numbers in the MNIST dataset. Take an arbitrary</p><p>image and its respective label vector yi. In order to construct</p><p>positive data samples we one-hot encode yi and replace the</p><p>first pixels of the image with the generated one-hot vector.</p><p>To obtain a negative data sample from the chosen image we</p><p>randomly pick a label that is not yi, e.g. yj ∈ Y , i ̸= j</p><p>and one-hot encode it. We then replace the first pixels of the</p><p>image with the generated one-hot vector of the wrong label</p><p>yj . Thus positive samples are overlaid with the correct label</p><p>and negative samples with an incorrect one. In contrast to the</p><p>usual backpropagation training, the FF algorithm operates</p><p>with two forward passes of the network. One positive pass</p><p>to adjust the weights of the hidden layer, al 1, such that</p><p>the goodness of each layer, gl(x) = P</p><p>j(al(x))2j</p><p>, increases</p><p>for positive samples above a defined threshold value θ and</p><p>one negative pass to decrease the goodness of the negative</p><p>samples below the value of θ. During a pass through the</p><p>network the output of each hidden layer is normalized to</p><p>only transmit the relative information and not the explicit</p><p>“goodness”-value from layer to layer.</p><p>The overall loss is</p><p>CFF = Cl</p><p>pos + Cl</p><p>neg =</p><p>ln[1 + exp(θ − gl(xpos))] + ln[1 + exp(gl(xneg) − θ)] (1)</p><p>After the entire model has been trained under the “goodness”</p><p>loss (1), the inference phase can be initiated by two</p><p>different methods, referred to as one-pass inference and</p><p>multi-pass inference. The “one-pass” inference works by</p><p>training a unique SoftMax/Sigmoid layer with a general</p><p>multi-classification loss function, such as the cross-entropy</p><p>loss, and with an input constructed by the activity vectors of</p><p>each of the layers conforming the original network (Fig. 1).</p><p>1Note that the output of a hidden layer is sometimes referred to as the</p><p>activity vector of that layer.</p><p>Fig. 1. Flow diagram for the one-pass inference step.</p><p>Hence the activity vectors from the second2 to the last layer</p><p>of the network are concatenated into a new vector that is later</p><p>on used as input for the SoftMax layer. The “multi-pass”</p><p>inference works with the structure of the trained network</p><p>but with multiple generated overlaid images as input. We</p><p>employ the same procedure from the generation of positive</p><p>and negative data to create N possible overlaid images for</p><p>each one of the N available labels. The overlaid images</p><p>are then used one at a time in the forward pass, and the</p><p>associated goodness values for each layer are collected and</p><p>added up. By sampling all the possible overlaid images we</p><p>can collect the goodness for each layer and with the use of</p><p>an argmax function determine the final label of the image</p><p>(Fig. 1).</p><p>Fig. 2. Flow diagram for the multi-pass inference step.</p><p>B. Variations to the algorithm</p><p>Along with the several improvements to the model topology</p><p>while using the original FF algorithm there are several</p><p>other approaches that try to deal with some of its weaknesses.</p><p>We classify them according to the components that built the</p><p>algorithm, starting from the creation of better correlated input</p><p>data, improved training loss functions, more effective training</p><p>routines, and faster inference schemes.</p><p>a) Creation of input data: According to Hinton the creation</p><p>of negative input data must be generated such that they</p><p>2It was shown that using the first hidden layer as part of input in the</p><p>linear classifier leads to worse performance in the predictions [1].</p><p>have different long-range correlations but very similar shortrange</p><p>correlations3. When working with convolutional neural</p><p>networks (CNN) this is more challenging, since the label</p><p>information must be present over the entire image, ensuring</p><p>that the multiple filters applied in each layer can capture</p><p>features of the original image as well as the information</p><p>on the classification space. One way of creating the data is</p><p>given by Scodellaro [3], where a spatially extended labeling</p><p>technique is used. The technique introduces a superposition</p><p>of the training dataset image with a second image of 2D</p><p>Fourier modes of the same size as the training image.</p><p>The mapping between labels and the specific wavelength,</p><p>amplitude, and orientation of the Fourier modes is chosen</p><p>freely. Thus generating as many different waves as labels</p><p>used in the classification problem. In other studies the authors</p><p>employ simple learnable embeddings for the same purpose</p><p>[2], [4]. However, further details on the correlations from</p><p>the generated images with such techniques are still lacking</p><p>from the original papers. Another approach is presented by</p><p>Xing Chen [5]. The creation of positive and negative samples</p><p>is based on the principles of Noise Contrastive Estimation,</p><p>where a pairing of positive+positive and positive+negative</p><p>samples are used as inputs to the network.</p><p>One final approach consist on the substitution of a positive</p><p>and negative samples with convolutional group channels.</p><p>Here the output of each convolutional layer used in the</p><p>network Y ∈ RN×C×H×W4 is subdivided into group input</p><p>channels ˆ Yj ∈ RN×S×H×W, where S = C/J and J corresponds</p><p>to the numbers of classes present in the classification</p><p>problem. In this construction an holistic goodness factor for</p><p>each layer is defined as</p><p>Gn,j = 1</p><p>S × H ×W</p><p>XS</p><p>s=1</p><p>XH</p><p>h=1</p><p>WX</p><p>w=1</p><p>ˆ Y 2</p><p>n,j,s,h,w (2)</p><p>and subsequently an associated positive and negative goodness</p><p>can be calculated for each convolutional layer, as gpos =</p><p>G·ZT and gneg = G· (1−ZT ), having thus Z ∈ {0, 1}N×J</p><p>as the one-hot encoded vector of the true labels [6].</p><p>b) Loss functions: Variations of the loss function (1)</p><p>are considered under the scope of distance metric learning,</p><p>where the construction of task specific distance spaces gives</p><p>better control on the distances from the data samples and</p><p>their respective classes. New loss functions directly measure</p><p>the discrepancy between projections of input patterns and</p><p>labels. One such measure is given by Thomas Doom [4]</p><p>where the Symba loss function has the disappearance of</p><p>a threshold variable, and the direct difference in between</p><p>positive and negative goodness values reinforces the discrepancies</p><p>between highly correlated positive and negative</p><p>samples. Furthermore, Yujie Wu proposes a loss function that</p><p>introduces a mixture between absolute and relative distances</p><p>from the goodness measures [2]. In the case of convolutional</p><p>3In the case of classical multi-layer perceptons (MLP) this can be easily</p><p>achieve with the procedure mentioned in Section II-A.</p><p>4We work with the NCHW format, where N : Number of data samples</p><p>in the batch, C : Image channels, H : Image height, W : Image width.</p><p>channel-wise competitive learning the team from Andreas</p><p>Papachristodoulou introduces a channel-wise loss function,</p><p>defined as,</p><p>Cl = −</p><p>1</p><p>N</p><p>XN</p><p>n=1</p><p>log</p><p> </p><p>exp(gpos</p><p>n )</p><p>PL</p><p>l=1 exp(Gn,j)</p><p>!</p><p>, (3)</p><p>that supports competitive learning though the channel dimension,</p><p>where the probability of the target class over the total</p><p>goodness score for each sample is calculated [6].</p><p>c) Training routines: Based on research for parallel training</p><p>in neural networks there have been explorations on</p><p>architectures that benefit from allowing error signals to propagate</p><p>through a neural network during training [7], [8]. By</p><p>studying different training architectures on layer-wise trained</p><p>models it has been shown that these architectures can lead</p><p>to an asynchronous layer-wise parallelism with low memory</p><p>footprint. The training architectures can be split into four</p><p>types: 1) the traditional backpropagation, 2) the greedy local</p><p>update5, 3) the overlapping local update, and 4) the chunked</p><p>local update. In these architectures, each group of layers is</p><p>trained independently and learned through an auxiliary loss</p><p>function which updates the weights within the group. On</p><p>the overlapping local update, the network is trained under</p><p>a series of overlapped n-layers from the original network</p><p>and conformed by n-subsequent layers, in which every new</p><p>group takes the last layer from the previous group as its</p><p>initial layer. The chunked local update proceeds in building</p><p>several chunks of n-layers sequentially ordered through the</p><p>entire network without overlapping with other layers. To</p><p>further enhance biological plausibility there are suggestions</p><p>on integrating random direct feedback connections on the</p><p>blocks to replace the back-propagation step and directly use</p><p>the calculated loss functions to update all relevant weights</p><p>[2].</p><p>d) Faster inference: One can infer that employing all activity</p><p>vectors of a trained neural network could be inefficient,</p><p>thus improved algorithms tackle this problem by directly</p><p>employing the predictions estimated from each layer or a</p><p>group of layers building the network. In the original paper,</p><p>the model uses the activity vectors from the second to last</p><p>layer, however, in more complex neural networks it has been</p><p>found that initial layers either jeopardize or are superfluous</p><p>to the final prediction. In newer models, the best results are</p><p>found by considering the final layer or the last three layers of</p><p>the model [4]. Other studies explore methods for achieving</p><p>lightweight inference using a confidence variable in each</p><p>layer to stop the inclusion of further activity vectors within</p><p>the model, and consequently achieving faster inference times</p><p>[9].</p><p>Even though the original purpose of the algorithm focuses</p><p>on its use in classification problems, the range of</p><p>applicability of the algorithm or its underlying principles is</p><p>investigated for unsupervised learning as well. In one study</p><p>the proposed models, referred to as Unsupervised learning</p><p>Forward-Forward models (UFF), allow training with usual</p><p>5Which in this case corresponds to the FF original training procedure.</p><p>loss functions and without special inputs [10]. The models</p><p>are built up with cells instead of layers and are based on</p><p>different unsupervised deep learning models, ranging from</p><p>an auto-encoder FF cell to a generative adversarial network</p><p>FF cell, leading to a better performance and stability. The</p><p>principles of the FF algorithm have been used to develop</p><p>a novel variance-capturing FF auto-encoder that allows to</p><p>efficiently update data-driven models in real-time [11]. The</p><p>study finally, highlights the model’s capacity to learn fault</p><p>detection and isolation in process industries based on FF</p><p>learning principles.</p><p>III. RESULTS &amp; ANALYSIS</p><p>We have worked with an improved algorithm that has the</p><p>following characteristics:</p><p>1) Creation of convolutional group channels for positive/</p><p>negative sampling (Figure 3).</p><p>2) Use of the channel-wise loss function (3).</p><p>3) Training through chunked local updates that alternate</p><p>in between iterations.</p><p>4) Realization of inference based on the activity vectors</p><p>from the last two layers of the model.</p><p>Given the original and our improved algorithm the different</p><p>features explained in Section II-A and II-B are explored with</p><p>a series of tests that give a particular focus on the plausible</p><p>constructions of the network for the MNIST and CIFAR10</p><p>datasets. While working with the original algorithm we employed</p><p>for the MNIST dataset a topology of 784×500×100</p><p>for the MLP; and two convolutional layers of 32 and 64 filters</p><p>plus a linear layer of 256×100 for the CNN. For CIFAR10</p><p>we considered a topology of 3072 × 3072 × 2000 × 1000</p><p>for the MLP, and four convolutional layers of 128, 264,</p><p>512, 1024 filters for the CNN. Our results in Table I show</p><p>that the algorithm works correctly as a classifier and has</p><p>similar results when employing any of the two kinds of</p><p>inference options. One drawback of the one-pass inference</p><p>is the additional softmax training time required to obtain the</p><p>same order of error obtained from the multi-pass inference.</p><p>Nevertheless, our tests have shown that the traditional onepass</p><p>inference results in less error percentage and faster</p><p>inference times.</p><p>By adopting the improvements discussed in Section II-B</p><p>we repeated the same tests and obtained the results shown</p><p>in Table II. In the improvements we have employed a more</p><p>elaborate network topology [4] which was trained using 300</p><p>epochs, where each layer consists of a batch normalization</p><p>layer, followed by the convolution layer, a ReLU activation</p><p>function, and an optional maxpool layer. Hence using six</p><p>convolutional layers of 128, 264 to 512 filters, with three</p><p>maxpool applications. This model will be denominated by</p><p>the name FF deep.</p><p>The results obtained show a considerable reduction of test</p><p>error percentage by more than 20% with respect to the original</p><p>algorithm. However, the use of a multi-step learning rate</p><p>schedule was necessary for better stability and convergence</p><p>of the results. In our models, we have applied them with a</p><p>Fig. 3. Flow diagram for the inference step in our improved algorithm.</p><p>The black arrows emphasises the creation of group channels and the use of</p><p>the one-hot encoded matrix Z for the calculation of holistic goodness G.</p><p>Dataset Layers Inference Training Test Inference</p><p>Error [%] Error [%] Time [s]</p><p>MNIST MLP One-pass 8.6 8.0 0.6</p><p>MLP Multi-pass 7.3 7.2 2.2</p><p>CNN One-pass 4.5 4.4 0.1</p><p>CNN Multi-pass 4.9 5.0 1.9</p><p>CIFAR10 MLP One-pass 39.2 39.3 0.1</p><p>MLP Multi-pass 41.1 41.2 0.2</p><p>CNN One-pass 20.5 44.3 1.4</p><p>CNN Multi-pass 44.8 48.3 4.5</p><p>TABLE I</p><p>TEST RESULTS OF FF ALGORITHM FOR MNIST AND CIFAR10</p><p>DATASETS.</p><p>γ = 0.1 at the epochs 150 and 200.6 Additionally, the usage</p><p>of convolutional channel-wise competitive learning enables</p><p>faster inference times for the multi-pass scheme, however,</p><p>it is still subject to greater times depending on the number</p><p>of used activation vectors. This characteristic is nevertheless</p><p>avoided by the one-pass inference step because it’s only</p><p>dependent on the final trained model that initially considered</p><p>the number of activity vectors before training. Given</p><p>that the improved algorithm still conserves an independent</p><p>block structure during training, the benefits from efficient</p><p>hyperparameter-tuning of the models are still present in this</p><p>case.</p><p>The algorithm presents some specific characteristics that</p><p>make it very suitable for low-capacity hardware projects.</p><p>Firstly, the avoidance of backpropagation allows for fewer</p><p>gradients to be computed during training, and all activation</p><p>vectors do not need to be kept in memory for the backward</p><p>pass. This has the advantage that the model can learn</p><p>while pipelining sequential data through the network without</p><p>resorting to saving the activity vectors of intermediate layers</p><p>or propagating error derivatives. The FF algorithm simplifies</p><p>the computational process by making it less intensive and</p><p>more easily structured with the two forward passes. The</p><p>independent training of each layer or block presents better</p><p>6For the MultiStepLR class defined in pytorch, γ is associated with the</p><p>multiplicative factor of learning rate decay.</p><p>Dataset Layers Inference Training Test Inference</p><p>Error [%] Error [%] Time [s]</p><p>MNIST CNN One-pass 0.2 0.8 1.7</p><p>CNN Multi-pass 0.2 0.7 1.4</p><p>CIFAR10 CNN One-pass 1.1 18.8 2.1</p><p>CNN Multi-pass 1.9 18.2 1.8</p><p>TABLE II</p><p>TEST RESULTS OF IMPROVED FF ALGORITHM FOR MNIST AND</p><p>CIFAR10 DATASETS.</p><p>regulation on the hyperparameters of the model and thus</p><p>results generally in better convergence of its gradients. This</p><p>also prevents further propagation of vanishing or exploding</p><p>gradients to subsequent layers. The algorithm also has the</p><p>potential to be parallelizable due to the training independence</p><p>of each layers, leading to possible accelerations on parallel</p><p>computing architectures.</p><p>To tackle further implementations on low-capacity hardware</p><p>projects we have explored the possibilities of lighter</p><p>FF models based only on CNN layers with the mentioned</p><p>configuration of techniques. The goal was to achieve a noticeable</p><p>reduction on parameters, because the FF deep model</p><p>is based on an architecture in [4] where their shallow network</p><p>has trained 4,100,000 parameters for the last two activation</p><p>vectors in the inference phase. In Table III we show a list of</p><p>the studied light FF models along with the FF deep model</p><p>and their respective architectures. Similarly, in Table IV the</p><p>results on all the light FF models are provided. The models</p><p>present a test error of (21±6)% and consider a different range</p><p>of trainable parameters. Our smallest network FF tiny has</p><p>a reduction in parameters of 96% in respect to FF deep,</p><p>but is subject to the highest test error of 24.1%. In contrast,</p><p>FF optimal conserves a test error below 20% and a parameter</p><p>reduction of 81% in comparison to our largest model.</p><p>Model Channels; Trainable</p><p>name Kernel Size Parameters</p><p>FF tiny [3,50,50,50,50]; 164,706</p><p>[3,3,3,4]</p><p>FF small [3,50,50,70,70]; 239,266</p><p>[3,3,3,4]</p><p>FF medium [3,50,50,100,150]; 484,506</p><p>[3,3,3,4]</p><p>FF optimal [3,50,50,100,160,160]; 754,386</p><p>[3,3,3,4,3]</p><p>FF deep [3,130,130,260,260,260,510]; 4,131,346</p><p>[3,3,3,5,3,3]</p><p>TABLE III</p><p>ARCHITECTURES FROM THE LIGHT FF MODELS TRAINED WITH THE</p><p>IMPROVED FF ALGORITHM.</p><p>During training the models are trained using 50-70 epochs.</p><p>Such small value shows that the training methods employed</p><p>lead to quick convergences of the gradients. Nevertheless,</p><p>a careful use of the MultiStep learning schedule with 3-5</p><p>milestones in between the epochs and γ ∈ {0.1, 0.2}, pushes</p><p>the models to the optimal 18% test error. The process of</p><p>training was susceptible to unstable gradients that propagate</p><p>though the whole network given our training technique</p><p>because of our choice to obtain shallow networks. This set</p><p>of light FF models offers broad flexibility to realize further</p><p>analysis on low-power hardware, without giving up accuracy</p><p>on the models. In particular, we are employing this flexibility</p><p>in an upcoming work on verification and validation of FF</p><p>models.</p><p>Model Inference Training Test</p><p>name Error [%] Error [%]</p><p>FF tiny One-pass 15.3 24.4</p><p>Multi-pass 17.9 24.1</p><p>FF small One-pass 12.3 23.4</p><p>Multi-pass 14.8 23.1</p><p>FF medium One-pass 8.0 21.5</p><p>Multi-pass 10.1 20.7</p><p>FF optimal One-pass 2.0 19.6</p><p>Multi-pass 2.4 19.3</p><p>FF deep One-pass 1.2 18.8</p><p>Multi-pass 1.8 18.2</p><p>TABLE IV</p><p>TEST RESULTS OF LIGHT FF MODELS WITH THE IMPROVED FF</p><p>ALGORITHM USING THE CIFAR10 DATASET.</p><p>IV. CONCLUSION</p><p>The research on the Forward-Forward algorithm keeps</p><p>evolving into further areas of machine learning and pursues</p><p>more demanding tasks that are close to real-life applications.</p><p>The algorithm continues to show its great potential for usage</p><p>in low-power hardware given its capabilities of layer- or</p><p>block-wise training, and its simplified computational process.</p><p>In our results, we have seen that the improved algorithm</p><p>performs better than the original one. Moreover, it can handle</p><p>more challenging datasets without losing its flexibility. The</p><p>improvements in the generation of input data and training</p><p>routines open the possibility for different learning configurations</p><p>that allow a faster and more efficient flow of information</p><p>between the layers. However, the group architectures</p><p>must be limited since otherwise they could fall back into</p><p>traditional backpropagation and lose the benefits from the FF</p><p>architecture. The presented lighter FF models show how this</p><p>configuration of techniques leads to a broad range of smaller</p><p>models that still achieve low test error percentages within</p><p>(21±6)% and a number of number of trainable parameters</p><p>between 164,706 and 754,386. Hence, these models have a</p><p>high performance comparable to those analyzed in state-ofthe-</p><p>art FF papers while keeping a considerably smaller size.</p><p>As a next step, we will investigate the benefits provided by</p><p>these kinds of models to achieve complete verification and</p><p>validation of the neural network.</p><p>REFERENCES</p><p>[1] Geoffrey Hinton. The forward-forward algorithm: Some preliminary</p><p>investigations, 2022.</p><p>[2] Yujie Wu, Siyuan Xu, Jibin Wu, Lei Deng, Mingkun Xu, Qinghao</p><p>Wen, and Guoqi Li. Distance-forward learning: Enhancing the</p><p>forward-forward algorithm towards high-performance on-chip learning,</p><p>2024.</p><p>[3] Riccardo Scodellaro, Ajinkya Kulkarni, Frauke Alves, and Matthias</p><p>Schr¨oter. Training convolutional neural networks with the forwardforward</p><p>algorithm, 2024.</p><p>[4] Thomas Dooms, Ing Jyh Tsang, and Jose Oramas. The trifecta: Three</p><p>simple techniques for training deeper forward-forward networks, 2023.</p><p>[5] Xing Chen, Dongshu Liu, Jeremie Laydevant, and Julie Grollier. Selfcontrastive</p><p>forward-forward algorithm, 2024.</p><p>[6] Andreas Papachristodoulou, Christos Kyrkou, Stelios Timotheou, and</p><p>Theocharis Theocharides. Convolutional channel-wise competitive</p><p>learning for the forward-forward algorithm. In Proceedings of the</p><p>AAAI Conference on Artificial Intelligence, volume 38, pages 14536–</p><p>14544, 2024.</p><p>[7] Michael Laskin, Luke Metz, Seth Nabarro, Mark Saroufim, Badreddine</p><p>Noune, Carlo Luschi, Jascha Sohl-Dickstein, and Pieter Abbeel.</p><p>Parallel training of deep networks with local updates, 2021.</p><p>[8] Yuwen Xiong, Mengye Ren, and Raquel Urtasun. Loco: Local</p><p>contrastive representation learning. Advances in neural information</p><p>processing systems, 33:11142–11153, 2020.</p><p>[9] Amin Aminifar, Baichuan Huang, Azra Abtahi, and Amir Aminifar.</p><p>Lightff: Lightweight inference for forward-forward algorithm, 2024.</p><p>[10] Taewook Hwang, Hyein Seo, and Sangkeun Jung. Employing layerwised</p><p>unsupervised learning to lessen data and loss requirements in</p><p>forward-forward algorithms. arXiv preprint arXiv:2404.14664, 2024.</p><p>[11] Deepak Kumar, Umang Goswami, Hariprasad Kodamana, Manojkumar</p><p>Ramteke, and Prakash Kumar Tamboli. Variance-capturing</p><p>forward-forward autoencoder (vffae): A forward learning neural network</p><p>for fault detection and isolation of process data. Process Safety</p><p>and Environmental Protection, 178:176–194, 2023.</p></div><div class="flex self-end"><div tabindex="0" role="button" class=""><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-copy" data-testid="icon-html"></i></div></div></button></div></div></div></div><div class="flex flex-row w-full spacing-right false"><div class="prose ai-message w-full p-3"><div class="ai-content"><div class="assistant-name"><p>AI-Assistant: <strong>Summary Consultant</strong></p></div><h1>Summary of "On the Advancements of the Forward-Forward Algorithm"</h1>
<p><strong>Authors:</strong> Mauricio Ortiz Torres, Markus Lange, Arne P. Raulf<br>
<strong>Affiliation:</strong> German Aerospace Center (DLR), Institut for AI-Safety and Security, Germany</p>
<h2>Abstract</h2>
<p>The Forward-Forward (FF) algorithm, introduced by Geoffrey Hinton in 2022, has been enhanced to tackle complex machine learning tasks, notably improving performance on datasets like CIFAR10. Key improvements include:</p>
<ul>
<li><strong>Techniques Used:</strong> Convolutional channel grouping, learning rate schedules, and independent block structures during training.</li>
<li><strong>Performance Improvement:</strong> Achieved a 20% reduction in test error rates.</li>
<li><strong>Lightweight Models:</strong> Developed lighter models with test error rates ranging from (21±6)% and trainable parameters between 164,706 and 754,386.</li>
</ul>
<h2>Introduction</h2>
<ul>
<li>The FF algorithm is designed for low-power hardware applications, focusing on classification tasks with reduced memory consumption.</li>
<li>It utilizes two forward passes during training rather than traditional backpropagation, resulting in lower memory requirements.</li>
</ul>
<h2>The Forward-Forward (FF) Algorithm</h2>
<h3>A. Original Approach</h3>
<ul>
<li>Operates with two input spaces (positive and negative samples) created from the dataset.</li>
<li>Uses a "goodness" loss function to adjust weights based on the goodness of layer outputs for both positive and negative samples.</li>
</ul>
<h3>B. Variations to the Algorithm</h3>
<ol>
<li><strong>Input Data Creation:</strong>
<ul>
<li>Improved techniques for generating positive and negative samples to enhance correlation.</li>
</ul>
</li>
<li><strong>Loss Functions:</strong>
<ul>
<li>New loss functions focus on better control of distances between data samples and their classes.</li>
</ul>
</li>
<li><strong>Training Routines:</strong>
<ul>
<li>Explores parallel training architectures to enhance efficiency.</li>
</ul>
</li>
<li><strong>Faster Inference:</strong>
<ul>
<li>Techniques to reduce the number of activity vectors used for predictions to improve inference speed.</li>
</ul>
</li>
</ol>
<h3>C. Unsupervised Learning Applications</h3>
<ul>
<li>The principles of the FF algorithm have been adapted for unsupervised learning, leading to the development of Unsupervised learning Forward-Forward models (UFF).</li>
</ul>
<h2>Results &amp; Analysis</h2>
<ul>
<li>Improved FF algorithm shows significant performance enhancements on MNIST and CIFAR10 datasets.</li>
<li>Comparison of original and improved algorithms indicates a reduction in test error percentages and faster inference times.</li>
<li>The improved algorithm maintains independent layer training, allowing for better hyperparameter tuning and convergence.</li>
</ul>
<h2>Lightweight Models</h2>
<ul>
<li>Developed several lighter FF models aimed at low-capacity hardware applications, achieving significant parameter reductions while maintaining low test error rates.</li>
<li>The FF tiny model shows a 96% reduction in parameters compared to the FF deep model, with a test error of 24.1%.</li>
</ul>
<h2>Conclusion</h2>
<ul>
<li>The FF algorithm continues to evolve, demonstrating its potential for low-power hardware applications and improved performance on complex tasks.</li>
<li>Future work will focus on verification and validation of these models.</li>
</ul>
<h2>Key Takeaways</h2>
<ul>
<li><strong>Performance:</strong> Improved FF algorithm reduces test errors significantly.</li>
<li><strong>Flexibility:</strong> Maintains flexibility with lightweight models suitable for low-capacity hardware.</li>
<li><strong>Future Research:</strong> Will explore the verification and validation of FF models.</li>
</ul>
<h2>Action Items</h2>
<ul>
<li>Investigate further applications and improvements of the FF algorithm.</li>
<li>Explore the implications of lightweight models in practical implementations.</li>
</ul></div><div class="msg-copy-ai"><div tabindex="0" role="button" class=""><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-copy" data-testid="icon-html"></i></div></div></button></div></div></div></div><div class="p-1"></div></div></div></div><div class="input-container border-primary fwe-px-4 py-3 relative"><div class="flex flex-row justify-center w-full desktop-expand"><div class="flex flex-col justify-center w-full"><div></div><div class="bdai-input-container"><textarea class="resize-none fwe-scrollbar" rows="1" placeholder="Type your inquiry here, you can insert private company information too!" style="height: 36px;"></textarea><div class="flex flex-col justify-end pb-1"><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero fwe-btn-icon" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-file-paperclip text-xl" data-testid="icon-html"></i></div></div></button></div><div class="flex flex-col justify-end pb-1"><button type="button" class="fwe-btn bdai-btn fwe-disabled bdai-disabled fwe-btn-hero bdai-btn-hero" form="form1" disabled=""><div class=""><div class="inline-flex justify-center items-center"><div class="">Send</div></div></div></button></div></div><div><span class="bdai-input-hint">FestoGPT can make mistakes. Consider checking important information.</span></div><div class="flex flex-row gap-3 pt-1"><label class="fwe-checkbox-container" for="wenet-search"><input id="wenet-search" type="checkbox" name="wenet-search"><div class="fwe-checkbox-indicator-container"><div class="fwe-checkbox-indicator-background"></div></div><div class="fwe-checkbox-title"><p class="fwe-font-size-small">Ask WeNet (beta)</p></div></label><label class="fwe-checkbox-container" for="public-search"><input id="public-search" type="checkbox" name="public-search"><div class="fwe-checkbox-indicator-container"><div class="fwe-checkbox-indicator-background"></div></div><div class="fwe-checkbox-title"><p class="fwe-font-size-small">Bing search</p></div></label></div></div></div></div></div><div class="fwe-p-3 gap-3 toolbox-container border-primary toggle-toolbox" aria-hidden="false"><div class="toolbox-menu-title flex justify-between items-center"><p><strong>Toolbox</strong></p><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-close" data-testid="icon-html"></i><div class=""></div></div></div></button></div><hr><button class="navbar-menu-item"><div class="fwe-flex-grow-1"><div class="flex flex-row justify-between"><b>General AI-Assistants</b><i class="fwe-icon fwe-icon-arrows-right-2"></i></div></div></button><button class="navbar-menu-item"><div class="fwe-flex-grow-1"><div class="flex flex-row justify-between"><b>Prompt Assistant</b><i class="fwe-icon fwe-icon-arrows-right-2"></i></div></div></button><button class="navbar-menu-item"><div class="fwe-flex-grow-1"><div class="flex flex-row justify-between"><b>My Prompts</b><i class="fwe-icon fwe-icon-arrows-right-2"></i></div></div></button><div class="fwe-p-3 gap-3 toolbox-page"><div class="toolbox-menu-title flex justify-between items-center"><p><strong>General AI-Assistants</strong></p><button type="button" class="fwe-btn bdai-btn fwe-btn-link bdai-btn-link bdai-hover-hero" form="form1"><div class=""><div class="inline-flex justify-center items-center"><i class="fwe-icon fwe-icon-menu-close" data-testid="icon-html"></i><div class=""></div></div></div></button></div><hr><div class="flex flex-col gap-3"><div class="fwe-select-wrapper"><input class="fr-select-input" aria-hidden="true" tabindex="-1" value="summary"><div role="button" tabindex="0" class="fwe-select"><div class="fwe-select-content">Summary Consultant</div></div><label class="fwe-select-label" for="assistant">Assistant name</label><div class="fwe-select-underline"></div><div class="fwe-select-description">Select an assistant</div></div><label class="fwe-input-text bdai-input-text" for="description"><textarea id="description" class="overflow-y" readonly="" autocomplete="off" rows="10">My task is to help you summarize any given content in a concise and organized manner, with a focus on key takeaways and action items. My aim is to provide you with a clear and professional summary that captures the essential information. The summary should be logically structured and easy to understand, with appropriate formatting such as headings, subheadings, and bullet points.  The user may include additional requirements.</textarea><span class="fwe-input-text-label bdai-input-text-label">Task Description</span><span class="fwe-input-text-info bdai-input-text-info">Generated prompt content</span></label><button type="button" class="fwe-btn bdai-btn fwe-disabled bdai-disabled fwe-btn-hero bdai-btn-hero" form="form1" disabled=""><div class=""><div class="inline-flex justify-center items-center"><div class="">Activate Assistant</div></div></div></button></div></div></div></div></div></div><div class="fwe-snackbar-container"></div></div>
    <!--
      This HTML file is a template.
      If you open it directly in the browser, you will see an empty page.

      You can add webfonts, meta tags, or analytics to this file.
      The build step will place the bundled scripts into the <body> tag.

      To begin the development, run `npm start` or `yarn start`.
      To create a production bundle, use `npm run build` or `yarn build`.
    -->
    <script>
      if (global === undefined) {
        var global = window;
      }
    </script>
  

</body></html>